#coding:utf-8

import numpy as np
import scipy.sparse
import xgboost as xgb
import sys
import random
import ConfigParser
def mknfold(train,finaltrain,test,nfold = 5):
	fi = open(train,'r')
	ftr = open(finaltrain,'w')
	fte = open(test,'w')
	k = 1
	for l in fi:
		if random.randint(1,nfold)==k:
			fte.write(l)
		else:
			ftr.write(l)
	fi.close()
	ftr.close()
	fte.close()

source = '/Users/jackqiu/data/train.data'
finaltrain = '/Users/jackqiu/data/finaltrain.data'
testfile = '/Users/jackqiu/data/localtest.data'
predfile = '/Users/jackqiu/data/test.data'

mknfold(source,finaltrain,testfile)
# load file from text file, also binary buffer generated by xgboost
mytrain = xgb.DMatrix(source)
dtrain = xgb.DMatrix(finaltrain)
dtest = xgb.DMatrix(testfile)
pred = xgb.DMatrix(predfile)
# remove constant columns
remove = []
for col in dtrain.columns:
    if dtrain[col].std() == 0:
        remove.append(col)
mytrain.drop(remove, axis=1, inplace=True)
pred.drop(remove, axis=1, inplace=True)
dtrain.drop(remove, axis=1, inplace=True)
dtest.drop(remove, axis=1, inplace=True)
remove = []
c = dtrain.columns
for i in range(len(c)-1):
    v = dtrain[c[i]].values
    for j in range(i+1,len(c)):
        if np.array_equal(v,dtrain[c[j]].values):
            remove.append(c[j])
mytrain.drop(remove, axis=1, inplace=True)
pred.drop(remove, axis=1, inplace=True)
dtrain.drop(remove, axis=1, inplace=True)
dtest.drop(remove, axis=1, inplace=True)
#pred_file = sys.argv[3]

# parameters read from config file
cf = ConfigParser.ConfigParser()
cf.read('train.conf')
#print cf.sections()
depth = cf.getint('xgb', 'depth')
num_round = cf.getint('xgb', 'round');
eta = cf.getfloat('xgb', 'eta')
gamma = cf.getfloat('xgb', 'gamma')
lambda_para = cf.getfloat('xgb', 'lambda_para')
subsample = cf.getfloat('xgb', 'subsample')
colsample_bytree = cf.getfloat('xgb', 'colsample_bytree')

label = dtrain.get_label()
ratio = float(np.sum(label == 0)) / np.sum(label==1)

param = {
		 'max_depth':depth,
		 'eta':eta, 
		 'silent':1,
		 'objective':'binary:logistic',
		 'gamma':gamma,
		 'min_child_weight':4,
		 'lambda':lambda_para,
		 'scale_pos_weight':ratio,
		 'subsample':subsample,
		 'colsample_bytree':colsample_bytree,
		 'seed':2016,
		 'eval_metric':"auc"
		 }

watchlist  = [(dtrain,'train'), (dtest, 'test')]
bst = xgb.train(param, dtrain, num_round, watchlist)
bst.save_model('train.model')
bst2 = xgb.train(param,mytrain,num_round,watchlist)
# predict
pred_file = 'pred.txt'
preds = bst2.predict(pred) #, ntree_limit=bst.best_ntree_limit

with open(pred_file, 'w') as f:
    for pred in preds:
    	if pred > 1.0:
    		pred = 1.0
        f.write(str(pred)+'\n')
